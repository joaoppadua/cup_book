{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPCR0YYA1MZjtd4RjkEa1Uu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joaoppadua/cup_book/blob/main/RM_toy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AGG35L_OHC3-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. First, let's create a simple dataset class for paired comparisons\n",
        "class PreferenceDataset(Dataset):\n",
        "    def __init__(self, prompts, better_responses, worse_responses, max_length=512):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.prompts = prompts\n",
        "        self.better_responses = better_responses\n",
        "        self.worse_responses = worse_responses\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.prompts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Combine prompt with each completion\n",
        "        better_text = f\"{self.prompts[idx]} {self.better_responses[idx]}\"\n",
        "        worse_text = f\"{self.prompts[idx]} {self.worse_responses[idx]}\"\n",
        "\n",
        "        # Tokenize both sequences\n",
        "        better_encoded = self.tokenizer(better_text,\n",
        "                                      truncation=True,\n",
        "                                      max_length=self.max_length,\n",
        "                                      padding='max_length',\n",
        "                                      return_tensors='pt')\n",
        "\n",
        "        worse_encoded = self.tokenizer(worse_text,\n",
        "                                     truncation=True,\n",
        "                                     max_length=self.max_length,\n",
        "                                     padding='max_length',\n",
        "                                     return_tensors='pt')\n",
        "\n",
        "        return {\n",
        "            'better_input_ids': better_encoded['input_ids'].squeeze(),\n",
        "            'better_attention_mask': better_encoded['attention_mask'].squeeze(),\n",
        "            'worse_input_ids': worse_encoded['input_ids'].squeeze(),\n",
        "            'worse_attention_mask': worse_encoded['attention_mask'].squeeze(),\n",
        "        }"
      ],
      "metadata": {
        "id": "JdB6LyuLINx2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Create the Reward Model\n",
        "class RewardModel(nn.Module):\n",
        "    def __init__(self, base_model='bert-base-uncased'):\n",
        "        super().__init__()\n",
        "        # Load pretrained model as base\n",
        "        self.base_model = AutoModel.from_pretrained(base_model)\n",
        "        # Add a value head that outputs a single scalar\n",
        "        self.value_head = nn.Sequential(\n",
        "            nn.Linear(self.base_model.config.hidden_size, 1),\n",
        "            nn.Tanh()  # Bound values between -1 and 1\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Get the pooled output from base model\n",
        "        outputs = self.base_model(input_ids=input_ids,\n",
        "                                attention_mask=attention_mask)\n",
        "        pooled_output = outputs.last_hidden_state[:, 0, :]  # Use [CLS] token\n",
        "        # Calculate value\n",
        "        value = self.value_head(pooled_output)\n",
        "        return value.squeeze(-1)"
      ],
      "metadata": {
        "id": "zPBEtZfDISVD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss Function:\n",
        "\n",
        "$$\n",
        "\\text{loss}(\\theta) = -\\frac{1}{\\binom{K}{2}} \\mathbb{E}_{(x,y_w,y_l)\\sim D} [\\log(\\sigma(r_\\theta(x, y_w) - r_\\theta(x, y_l)))]\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "$\\theta$ represents the model parameters\n",
        "\n",
        "$K$ is the number of responses being ranked (4 to 9 in the paper)\n",
        "\n",
        "$x$ is the input prompt\n",
        "\n",
        "$y_w$ is the preferred (winning) completion\n",
        "\n",
        "$y_l$ is the less preferred (losing) completion\n",
        "\n",
        "$D$ is the dataset of human comparisons\n",
        "\n",
        "$r_\\theta$ is the reward model's output\n",
        "\n",
        "$\\sigma$ is the sigmoid function\n",
        "\n",
        "In this rendering, the normalization and the bias have been dropped, and a tanh function used to limit the value of the scalars."
      ],
      "metadata": {
        "id": "EJCHMXLjI_Uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Training function\n",
        "def train_reward_model(model, train_loader, epochs=10, lr=1e-5):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=f'Epoch {epoch+1}'):\n",
        "            # Move batch to device\n",
        "            better_input_ids = batch['better_input_ids'].to(device)\n",
        "            better_attention_mask = batch['better_attention_mask'].to(device)\n",
        "            worse_input_ids = batch['worse_input_ids'].to(device)\n",
        "            worse_attention_mask = batch['worse_attention_mask'].to(device)\n",
        "\n",
        "            # Get reward scores for both completions\n",
        "            better_score = model(better_input_ids, better_attention_mask)\n",
        "            worse_score = model(worse_input_ids, worse_attention_mask)\n",
        "\n",
        "            # Calculate loss (as described in the paper)\n",
        "            loss = -torch.log(torch.sigmoid(better_score - worse_score)).mean()\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch {epoch+1} average loss: {avg_loss:.4f}')"
      ],
      "metadata": {
        "id": "VN_hrIbtIYcr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Example usage\n",
        "\n",
        "# Create some toy data\n",
        "prompts = [\n",
        "    \"List a constitutional right in the First Amendment:\",\n",
        "    \"Explain the concept of gravity:\",\n",
        "    \"Describe the weather:\",\n",
        "    \"What is the capital of France?\",\n",
        "    \"Translate 'Hello, how are you?' into Spanish.\",\n",
        "    \"Write a short poem about nature.\",\n",
        "    \"Summarize the plot of Hamlet.\",\n",
        "    \"What are the main differences between a civil case and a criminal case?\", # Legal example\n",
        "    \"Explain the concept of 'habeas corpus' in law.\", # Legal example\n",
        "    \"Draft a simple contract for the sale of goods.\"  # Legal example\n",
        "]\n",
        "\n",
        "better_responses = [\n",
        "    \"Freedom of speech\",\n",
        "    \"Gravity is the force that attracts objects with mass towards each other.\",\n",
        "    \"Sunny with clear blue skies and a gentle breeze.\",\n",
        "    \"Paris\",\n",
        "    \"Hola, ¿cómo estás?\",\n",
        "    \"Green leaves whisper secrets to the wind, / A gentle stream flows where the flowers begin.\",\n",
        "    \"Hamlet, Prince of Denmark, seeks revenge against his uncle, Claudius, who murdered his father and married his mother.\",\n",
        "    \"In a civil case, two parties dispute a private matter, while in a criminal case, the government prosecutes an individual for a crime.\", # Legal example\n",
        "    \"'Habeas corpus' is a legal principle that protects individuals from unlawful imprisonment by requiring the government to justify their detention.\", # Legal example\n",
        "    \"This contract is for the sale of [goods] from [seller] to [buyer] for the price of [price].\"  # Legal example\n",
        "]\n",
        "\n",
        "worse_responses = [\n",
        "    \"Constitutional rights are very important\",\n",
        "    \"Things fall down because of gravity.\",\n",
        "    \"The weather is nice.\",\n",
        "    \"London\",\n",
        "    \"Hello, cómo eres?\",\n",
        "    \"Nature is beautiful\",\n",
        "    \"Hamlet is a play by Shakespeare.\",\n",
        "    \"Civil cases are easy, and criminal cases are hard.\", # Legal example\n",
        "    \"Habeas corpus is a Latin term.\", # Legal example\n",
        "    \"I agree to sell you stuff.\" # Legal example\n",
        "]\n",
        "\n",
        "# Create dataset and dataloader\n",
        "dataset = PreferenceDataset(prompts, better_responses, worse_responses)\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "# Initialize and train model\n",
        "model = RewardModel()\n",
        "train_reward_model(model, dataloader)\n",
        "\n",
        "# Example inference\n",
        "def get_reward_score(prompt, completion):\n",
        "    model.eval()\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # get the device\n",
        "    with torch.no_grad():\n",
        "        text = f\"{prompt} {completion}\"\n",
        "        encoded = dataset.tokenizer(text,\n",
        "                                  truncation=True,\n",
        "                                  max_length=512,\n",
        "                                  padding='max_length',\n",
        "                                  return_tensors='pt')\n",
        "        # move tensors to device\n",
        "        score = model(encoded['input_ids'].to(device), encoded['attention_mask'].to(device))\n",
        "        return score.item()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0YRhT6UIdVL",
        "outputId": "f9c8428b-7b72-464a-e990-3c78a594a9ee"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 5/5 [00:02<00:00,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 average loss: 0.7454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 5/5 [00:02<00:00,  2.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 average loss: 0.6035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 5/5 [00:02<00:00,  2.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 average loss: 0.5669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 5/5 [00:02<00:00,  2.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 average loss: 0.4998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 5/5 [00:02<00:00,  2.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 average loss: 0.4284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 5/5 [00:02<00:00,  2.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 average loss: 0.3764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 5/5 [00:02<00:00,  2.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 average loss: 0.2744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 5/5 [00:02<00:00,  2.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 average loss: 0.2504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 5/5 [00:02<00:00,  2.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 average loss: 0.2224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 5/5 [00:02<00:00,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 average loss: 0.1919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "prompt = \"Give me a constitutional right:\"\n",
        "completion1 = \"Freedom of expression\"\n",
        "completion2 = \"Some things are better than others\"\n",
        "\n",
        "score1 = get_reward_score(prompt, completion1)\n",
        "score2 = get_reward_score(prompt, completion2)\n",
        "print(f\"Score for completion 1: {score1:.4f}\")\n",
        "print(f\"Score for completion 2: {score2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8jRSH58-qje",
        "outputId": "896c4ac7-06a4-4132-857c-5d5d56c127c8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for completion 1: 0.7725\n",
            "Score for completion 2: -0.8029\n"
          ]
        }
      ]
    }
  ]
}