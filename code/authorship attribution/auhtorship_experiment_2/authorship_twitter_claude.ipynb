{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing authorship of tweets from Rihanna and Katy Perry using Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /Users/joaopedropadua/anaconda3/envs/cup/lib/python3.12/site-packages (4.66.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic\n",
    "from credentials import get_credentials_claude\n",
    "\n",
    "API_KEY = get_credentials_claude()\n",
    "\n",
    "client = Anthropic(api_key=API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "# load training data\n",
    "with open('./data/sampled_author_texts.pkl', 'rb') as f:\n",
    "    training_data = pickle.load(f)\n",
    "\n",
    "#load test data\n",
    "with open('./data/twitter_test.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's just beyond the vault. Discover room 7 of the #ANTIdiaRy at https://t.co/uJ0CLlhoaS https://t.co/povYOBn3Fm\n",
      "Author: rihanna\n"
     ]
    }
   ],
   "source": [
    "# Get a random tweet from the test set\n",
    "random_tweet_text = test_data['content'].sample(n=1, random_state=42).values[0]\n",
    "random_tweet_author = test_data.loc[test_data['content'] == random_tweet_text, 'author'].values[0]\n",
    "print(random_tweet_text)\n",
    "print(f\"Author: {random_tweet_author}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the template prompt\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are an expert in linguistic analysis and authorship attribution. Your task is to analyze authorship--i.e. idiolectal--markers that the \\\n",
    "texts reveal about their authors.\n",
    "\n",
    "\n",
    "You will be provided with:\n",
    "1. Training samples (tweets) from 2 different authors, Rihanna and Katy Perry\n",
    "2. A new text whose author you need to identify between those two authors\n",
    "\n",
    "Guideline for analysis:\n",
    "- Just use state of the art techniques to attribute authorship\n",
    "\n",
    "Rihanna's tweets:\n",
    "{training_data['rihanna']}\n",
    "\n",
    "Katy Perry's tweets:\n",
    "{training_data['katyperry']}\n",
    "\n",
    "New text to analyze:\n",
    "{random_tweet_text}\n",
    "\n",
    "Your answer should contain only the author's name and nothing else.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a completion function that will be used to query the model\n",
    "def get_completion(prompt: str, max_tokens=5000) -> str:\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20240620\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=max_tokens,\n",
    "        )\n",
    "    return response.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rihanna\n"
     ]
    }
   ],
   "source": [
    "first_prediction = get_completion(prompt)\n",
    "print(first_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual author: rihanna\n",
      "Predicted author: rihanna\n",
      "Prediction is correct: True\n",
      "Accuracy: 1\n"
     ]
    }
   ],
   "source": [
    "# Check if the prediction is accurate\n",
    "# Get the actual author of the random tweet\n",
    "actual_author = random_tweet_author.lower()\n",
    "\n",
    "# Get the predicted author from the model's response\n",
    "predicted_author = first_prediction.strip().lower()\n",
    "\n",
    "# Check if the prediction matches the actual author\n",
    "is_correct = predicted_author == actual_author\n",
    "\n",
    "print(f\"Actual author: {actual_author}\")\n",
    "print(f\"Predicted author: {predicted_author}\")\n",
    "print(f\"Prediction is correct: {is_correct}\")\n",
    "\n",
    "# Calculate accuracy (1 for correct, 0 for incorrect)\n",
    "accuracy = 1 if is_correct else 0\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m actual_authors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m invalid_outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampled_tweets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterrows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msampled_tweets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProcessing tweets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     10\u001b[0m     tweet_text \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m     actual_author \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/cup/lib/python3.12/site-packages/tqdm/notebook.py:234\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m unit_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    233\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m*\u001b[39m unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n\u001b[0;32m--> 234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cup/lib/python3.12/site-packages/tqdm/notebook.py:108\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[1;32m    110\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m IProgress(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mtotal)\n",
      "\u001b[0;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sampled_tweets = test_data.sample(n=50, random_state=42).reset_index(drop=True)\n",
    "\n",
    "predicted_authors = []\n",
    "actual_authors = []\n",
    "invalid_outputs = []\n",
    "\n",
    "for idx, row in tqdm(sampled_tweets.iterrows(), total=len(sampled_tweets), desc=\"Processing tweets\"):\n",
    "    tweet_text = row['content']\n",
    "    actual_author = row['author']\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are an expert in linguistic analysis and authorship attribution. Your task is to analyze authorship--i.e. idiolectal--markers that the \\\\\n",
    "texts reveal about their authors.\n",
    "\n",
    "You will be provided with:\n",
    "1. Training samples (tweets) from 2 different authors, Rihanna and Katy Perry\n",
    "2. A new text whose author you need to identify between those two authors\n",
    "\n",
    "Guideline for analysis:\n",
    "- Just use state of the art techniques to attribute authorship\n",
    "\n",
    "Rihanna's tweets:\n",
    "{training_data['rihanna']}\n",
    "\n",
    "Katy Perry's tweets:\n",
    "{training_data['katyperry']}\n",
    "\n",
    "New text to analyze:\n",
    "{tweet_text}\n",
    "\n",
    "Your answer should contain only the author's name and nothing else.\n",
    "\n",
    "\"\"\"\n",
    "    prediction = get_completion(prompt).strip().lower()\n",
    "    if prediction not in ['rihanna', 'katyperry']:\n",
    "        invalid_outputs.append((idx, prediction, tweet_text))\n",
    "    predicted_authors.append(prediction)\n",
    "    actual_authors.append(actual_author.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy (only for valid outputs)\n",
    "valid_indices = [i for i, pred in enumerate(predicted_authors) if pred in ['rihanna', 'katyperry']]\n",
    "valid_preds = [predicted_authors[i] for i in valid_indices]\n",
    "valid_actuals = [actual_authors[i] for i in valid_indices]\n",
    "\n",
    "correct = sum(p == a for p, a in zip(valid_preds, valid_actuals))\n",
    "total = len(valid_actuals)\n",
    "accuracy = correct / total if total > 0 else 0\n",
    "\n",
    "print(f\"Accuracy (on valid outputs): {accuracy:.2%} ({correct}/{total})\")\n",
    "print(f\"Number of invalid outputs: {len(invalid_outputs)}\")\n",
    "\n",
    "# Optionally, print invalid outputs\n",
    "if invalid_outputs:\n",
    "    print(\"\\nInvalid outputs (index, prediction, tweet):\")\n",
    "    for idx, pred, tweet in invalid_outputs:\n",
    "        print(f\"Index {idx}: Prediction='{pred}' | Tweet='{tweet}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
