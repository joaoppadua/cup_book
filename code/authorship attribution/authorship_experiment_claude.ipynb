{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blog Authorship Corpus Exercise (Part 2)\n",
    "\n",
    "This notebook will use the Kaggle blog dataset prepared in other notebook to assess whether Claude can identify authorship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting anthropic\n",
      "  Downloading anthropic-0.49.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from anthropic)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from anthropic)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from anthropic)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from anthropic)\n",
      "  Downloading jiter-0.9.0-cp312-cp312-macosx_10_12_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/joaopedropadua/anaconda3/envs/cup/lib/python3.12/site-packages (from anthropic) (2.9.2)\n",
      "Collecting sniffio (from anthropic)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /Users/joaopedropadua/anaconda3/envs/cup/lib/python3.12/site-packages (from anthropic) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/joaopedropadua/anaconda3/envs/cup/lib/python3.12/site-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/joaopedropadua/anaconda3/envs/cup/lib/python3.12/site-packages (from httpx<1,>=0.23.0->anthropic) (2024.8.30)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->anthropic)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->anthropic)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/joaopedropadua/anaconda3/envs/cup/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/joaopedropadua/anaconda3/envs/cup/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.23.4)\n",
      "Downloading anthropic-0.49.0-py3-none-any.whl (243 kB)\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.9.0-cp312-cp312-macosx_10_12_x86_64.whl (309 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: sniffio, jiter, h11, distro, httpcore, anyio, httpx, anthropic\n",
      "Successfully installed anthropic-0.49.0 anyio-4.9.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jiter-0.9.0 sniffio-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from credentials import get_credentials_claude\n",
    "from anthropic import Anthropic\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = get_credentials_claude()\n",
    "client = Anthropic(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a completion function that will be used to query the model\n",
    "def get_completion(prompt, max_tokens=1000):\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20240620\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=max_tokens,)\n",
    "    return response.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "with open('train_set.pkl', 'rb') as f:\n",
    "    train_set = pickle.load(f)\n",
    "\n",
    "with open('test_set.pkl', 'rb') as f:\n",
    "    test_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>text_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>449628</td>\n",
       "      <td>male</td>\n",
       "      <td>34</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,June,2003</td>\n",
       "      <td>urlLink A Day in the Country 20...</td>\n",
       "      <td>4221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>449628</td>\n",
       "      <td>male</td>\n",
       "      <td>34</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Aries</td>\n",
       "      <td>20,February,2003</td>\n",
       "      <td>urlLink DE Japan : Resources : Career...</td>\n",
       "      <td>4221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>734562</td>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Libra</td>\n",
       "      <td>03,August,2004</td>\n",
       "      <td>You ain't fat!  You ain't nothin'! ...</td>\n",
       "      <td>2301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>734562</td>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Libra</td>\n",
       "      <td>03,August,2004</td>\n",
       "      <td>so no one was amused by the old JLS...</td>\n",
       "      <td>2301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>i'm sorry that i didn't let the gro...</td>\n",
       "      <td>2294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  gender  age       topic   sign              date  \\\n",
       "0  449628    male   34      indUnk  Aries      05,June,2003   \n",
       "1  449628    male   34      indUnk  Aries  20,February,2003   \n",
       "2  734562  female   24        Arts  Libra    03,August,2004   \n",
       "3  734562  female   24        Arts  Libra    03,August,2004   \n",
       "4  589736    male   35  Technology  Aries    05,August,2004   \n",
       "\n",
       "                                                text  text_count  \n",
       "0                 urlLink A Day in the Country 20...        4221  \n",
       "1           urlLink DE Japan : Resources : Career...        4221  \n",
       "2             You ain't fat!  You ain't nothin'! ...        2301  \n",
       "3             so no one was amused by the old JLS...        2301  \n",
       "4             i'm sorry that i didn't let the gro...        2294  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So I need to create a prompt that will connect the \"text\" column with the \"id\" column in the train set and then ask about a random text in the test set and have the model try to guess from which id it came from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pairs or ids and texts to use them as variables in the prompt\n",
    "train_pairs = train_set[['id', 'text']].to_dict(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get a list of author ids\n",
    "author_ids = train_set['id'].unique()\n",
    "len(author_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pairs[2]['id'] == train_pairs[3]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First select a random row from test_set\n",
    "random_row = test_set.sample(n=1, random_state=42)  # random_state for reproducibility\n",
    "random_text = random_row['text'].iloc[0]\n",
    "random_id = random_row['id'].iloc[0]  # We'll keep this to check if the model's prediction is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First version of the prompt\n",
    "prompt = f\"\"\"\n",
    "You are an authorship analysis expert. You will be given examples of two texts from each of 10 different authors.\\\n",
    "You should read the samples carefully and identify linguistic features that distinguish one author from the others.\\\n",
    "Then you will be given a new text, and your job is to identify which author it most likely belongs to.\n",
    "\n",
    "Here are the authors and the texts:\n",
    "<author_samples>\n",
    "<author_id>\n",
    "{train_pairs[0]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[0]['text']}\n",
    "{train_pairs[1]['text']}\n",
    "</text>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[2]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[2]['text']}\n",
    "{train_pairs[3]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[4]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[4]['text']}\n",
    "{train_pairs[5]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[6]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[6]['text']}\n",
    "{train_pairs[7]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[8]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[8]['text']}\n",
    "{train_pairs[9]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[10]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[10]['text']}\n",
    "{train_pairs[11]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[12]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[12]['text']}\n",
    "{train_pairs[13]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[14]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[14]['text']}\n",
    "{train_pairs[15]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[16]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[16]['text']}\n",
    "{train_pairs[17]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[18]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[18]['text']}\n",
    "{train_pairs[19]['text']}\n",
    "</texts>\n",
    "\n",
    "</author_samples>\n",
    "\n",
    "Now you will be given a new text, and your job is to identify which author it most likely belongs to.\n",
    "\n",
    "<new_text>\n",
    "{random_text}\n",
    "</new_text>\n",
    "\n",
    "Present your answer in the following format:\n",
    "<answer>\n",
    "Author ID: [Your prediction]\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Improved version (with LLM help)\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are an expert in linguistic analysis and authorship attribution. Your task is to analyze writing styles and identify the author of a given text.\n",
    "\n",
    "You will be provided with:\n",
    "1. Training samples from 10 different authors (2 texts per author)\n",
    "2. A new text whose author you need to identify\n",
    "\n",
    "Guidelines for analysis:\n",
    "- Pay attention to writing style elements like:\n",
    "  * Vocabulary choice and complexity\n",
    "  * Sentence structure and length\n",
    "  * Punctuation patterns\n",
    "  * Common phrases or expressions\n",
    "  * Topic preferences\n",
    "  * Tone and voice\n",
    "  * Grammar patterns\n",
    "- Consider both obvious and subtle patterns\n",
    "- Look for consistent features across an author's texts\n",
    "- Note any unique or distinctive elements\n",
    "\n",
    "Here are the training samples:\n",
    "\n",
    "<author_samples>\n",
    "<author_id>\n",
    "{train_pairs[0]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[0]['text']}\n",
    "{train_pairs[1]['text']}\n",
    "</text>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[2]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[2]['text']}\n",
    "{train_pairs[3]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[4]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[4]['text']}\n",
    "{train_pairs[5]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[6]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[6]['text']}\n",
    "{train_pairs[7]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[8]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[8]['text']}\n",
    "{train_pairs[9]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[10]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[10]['text']}\n",
    "{train_pairs[11]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[12]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[12]['text']}\n",
    "{train_pairs[13]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[14]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[14]['text']}\n",
    "{train_pairs[15]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[16]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[16]['text']}\n",
    "{train_pairs[17]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[18]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[18]['text']}\n",
    "{train_pairs[19]['text']}\n",
    "</texts>\n",
    "</author_samples>\n",
    "\n",
    "Now, analyze this new text and identify which author it most likely belongs to. Provide your reasoning by briefly explaining which linguistic features led you to your conclusion.\n",
    "\n",
    "<new_text>\n",
    "{random_text}\n",
    "</new_text>\n",
    "\n",
    "Please provide your answer in this format:\n",
    "Author ID: [predicted_id]\n",
    "Reasoning: [explanation of your analysis]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author ID: 303162\n",
      "\n",
      "Reasoning:\n",
      "\n",
      "The writing style in this new text most closely matches that of author 303162. Here's why:\n",
      "\n",
      "1. Sentence structure: The author uses a mix of longer, complex sentences and shorter, punchy ones. This is similar to the sample from 303162, which also shows varied sentence lengths.\n",
      "\n",
      "2. Stream of consciousness style: The text flows in a somewhat rambling, introspective manner, similar to 303162's style in their samples. There's a sense of the author thinking out loud and exploring their thoughts as they write.\n",
      "\n",
      "3. Use of parenthetical asides: The author uses parentheses to add extra thoughts, which is also seen in 303162's writing (\"(!) Bisi.\").\n",
      "\n",
      "4. Casual tone: The writing has an informal, conversational tone, using phrases like \"One more thing:\" and \"Silly chronicles of life.\" This matches the casual style seen in 303162's samples.\n",
      "\n",
      "5. Personal anecdotes: The text focuses on a personal experience (a dream), which aligns with 303162's tendency to share personal stories and daily experiences.\n",
      "\n",
      "6. Use of URLs: The author includes a URL link, which is also present in 303162's samples.\n",
      "\n",
      "7. Reflection on mundane events: The author reflects on everyday occurrences (like dreaming and waking up), which is similar to 303162's style of discussing daily activities.\n",
      "\n",
      "8. Music reference: The author mentions a specific song and artist, which aligns with 303162's reference to music in their samples (\"'Here Comes the Sun'. Only one of the best Beatles songs ever!!\").\n",
      "\n",
      "While some other authors show similar casual tones or use of URLs, the combination of these features, particularly the stream of consciousness style and reflection on daily life, most strongly points to author 303162.\n"
     ]
    }
   ],
   "source": [
    "first_prediction = get_completion(prompt)\n",
    "print(first_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1107146)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the accuracy of the model's prediction\n",
    "random_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
