{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blog Authorship Corpus Exercise (Part 2)\n",
    "\n",
    "This notebook will use the Kaggle blog dataset prepared in other notebook to assess whether Claude can identify authorship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting anthropic\n",
      "  Downloading anthropic-0.49.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from anthropic)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from anthropic)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from anthropic)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from anthropic)\n",
      "  Downloading jiter-0.9.0-cp312-cp312-macosx_10_12_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/joaopedropadua/anaconda3/envs/cup/lib/python3.12/site-packages (from anthropic) (2.9.2)\n",
      "Collecting sniffio (from anthropic)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /Users/joaopedropadua/anaconda3/envs/cup/lib/python3.12/site-packages (from anthropic) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/joaopedropadua/anaconda3/envs/cup/lib/python3.12/site-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/joaopedropadua/anaconda3/envs/cup/lib/python3.12/site-packages (from httpx<1,>=0.23.0->anthropic) (2024.8.30)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->anthropic)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->anthropic)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/joaopedropadua/anaconda3/envs/cup/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/joaopedropadua/anaconda3/envs/cup/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.23.4)\n",
      "Downloading anthropic-0.49.0-py3-none-any.whl (243 kB)\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.9.0-cp312-cp312-macosx_10_12_x86_64.whl (309 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: sniffio, jiter, h11, distro, httpcore, anyio, httpx, anthropic\n",
      "Successfully installed anthropic-0.49.0 anyio-4.9.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jiter-0.9.0 sniffio-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from credentials import get_credentials_claude\n",
    "from anthropic import Anthropic\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = get_credentials_claude()\n",
    "client = Anthropic(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a completion function that will be used to query the model\n",
    "def get_completion(prompt, max_tokens=1000):\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20240620\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=max_tokens,)\n",
    "    return response.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "with open('train_set.pkl', 'rb') as f:\n",
    "    train_set = pickle.load(f)\n",
    "\n",
    "with open('test_set.pkl', 'rb') as f:\n",
    "    test_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>text_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>449628</td>\n",
       "      <td>male</td>\n",
       "      <td>34</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,June,2003</td>\n",
       "      <td>urlLink A Day in the Country 20...</td>\n",
       "      <td>4221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>449628</td>\n",
       "      <td>male</td>\n",
       "      <td>34</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Aries</td>\n",
       "      <td>20,February,2003</td>\n",
       "      <td>urlLink DE Japan : Resources : Career...</td>\n",
       "      <td>4221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>734562</td>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Libra</td>\n",
       "      <td>03,August,2004</td>\n",
       "      <td>You ain't fat!  You ain't nothin'! ...</td>\n",
       "      <td>2301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>734562</td>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Libra</td>\n",
       "      <td>03,August,2004</td>\n",
       "      <td>so no one was amused by the old JLS...</td>\n",
       "      <td>2301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>i'm sorry that i didn't let the gro...</td>\n",
       "      <td>2294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  gender  age       topic   sign              date  \\\n",
       "0  449628    male   34      indUnk  Aries      05,June,2003   \n",
       "1  449628    male   34      indUnk  Aries  20,February,2003   \n",
       "2  734562  female   24        Arts  Libra    03,August,2004   \n",
       "3  734562  female   24        Arts  Libra    03,August,2004   \n",
       "4  589736    male   35  Technology  Aries    05,August,2004   \n",
       "\n",
       "                                                text  text_count  \n",
       "0                 urlLink A Day in the Country 20...        4221  \n",
       "1           urlLink DE Japan : Resources : Career...        4221  \n",
       "2             You ain't fat!  You ain't nothin'! ...        2301  \n",
       "3             so no one was amused by the old JLS...        2301  \n",
       "4             i'm sorry that i didn't let the gro...        2294  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So I need to create a prompt that will connect the \"text\" column with the \"id\" column in the train set and then ask about a random text in the test set and have the model try to guess from which id it came from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pairs or ids and texts to use them as variables in the prompt\n",
    "train_pairs = train_set[['id', 'text']].to_dict(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get a list of author ids\n",
    "author_ids = train_set['id'].unique()\n",
    "len(author_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First select a random row from test_set\n",
    "random_row = test_set.sample(n=1, random_state=42)  # random_state for reproducibility\n",
    "random_text = random_row['text'].iloc[0]\n",
    "random_id = random_row['id'].iloc[0]  # We'll keep this to check if the model's prediction is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First version of the prompt\n",
    "prompt = f\"\"\"\n",
    "You are an authorship analysis expert. You will be given examples of two texts from each of 10 different authors.\\\n",
    "You should read the samples carefully and identify linguistic features that distinguish one author from the others.\\\n",
    "Then you will be given a new text, and your job is to identify which author it most likely belongs to.\n",
    "\n",
    "Here are the authors and the texts:\n",
    "<author_samples>\n",
    "<author_id>\n",
    "{train_pairs[0]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[0]['text']}\n",
    "{train_pairs[1]['text']}\n",
    "</text>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[2]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[2]['text']}\n",
    "{train_pairs[3]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[4]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[4]['text']}\n",
    "{train_pairs[5]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[6]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[6]['text']}\n",
    "{train_pairs[7]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[8]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[8]['text']}\n",
    "{train_pairs[9]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[10]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[10]['text']}\n",
    "{train_pairs[11]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[12]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[12]['text']}\n",
    "{train_pairs[13]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[14]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[14]['text']}\n",
    "{train_pairs[15]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[16]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[16]['text']}\n",
    "{train_pairs[17]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[18]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[18]['text']}\n",
    "{train_pairs[19]['text']}\n",
    "</texts>\n",
    "\n",
    "</author_samples>\n",
    "\n",
    "Now you will be given a new text, and your job is to identify which author it most likely belongs to.\n",
    "\n",
    "<new_text>\n",
    "{random_text}\n",
    "</new_text>\n",
    "\n",
    "Present your answer in the following format:\n",
    "<answer>\n",
    "Author ID: [Your prediction]\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Improved version (with LLM help)\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are an expert in linguistic analysis and authorship attribution. Your task is to analyze authorship--i.e. idiolectal--markers that the \\\n",
    "texts reveal about their authors.\n",
    "\n",
    "\n",
    "You will be provided with:\n",
    "1. Training samples from 10 different authors (2 texts per author)\n",
    "2. A new text whose author you need to identify\n",
    "\n",
    "Guidelines for analysis:\n",
    "- Pay attention to writing style elements\n",
    "- Note especially the grammatical structure of the text and grammatical items, such as\\\n",
    "connectors, prepositions, verbs, phrases, idioms, collocations, etc.\n",
    "- Consider both obvious and subtle patterns\n",
    "- Look for consistent features across an author's texts\n",
    "- Consider any unique or distinctive elements\n",
    "\n",
    "\n",
    "Here are the training samples:\n",
    "\n",
    "<author_samples>\n",
    "<author_id>\n",
    "{train_pairs[0]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[0]['text']}\n",
    "{train_pairs[1]['text']}\n",
    "</text>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[2]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[2]['text']}\n",
    "{train_pairs[3]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[4]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[4]['text']}\n",
    "{train_pairs[5]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[6]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[6]['text']}\n",
    "{train_pairs[7]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[8]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[8]['text']}\n",
    "{train_pairs[9]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[10]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[10]['text']}\n",
    "{train_pairs[11]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[12]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[12]['text']}\n",
    "{train_pairs[13]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[14]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[14]['text']}\n",
    "{train_pairs[15]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[16]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[16]['text']}\n",
    "{train_pairs[17]['text']}\n",
    "</texts>\n",
    "\n",
    "<author_id>\n",
    "{train_pairs[18]['id']}\n",
    "</author_id>\n",
    "<texts>\n",
    "{train_pairs[18]['text']}\n",
    "{train_pairs[19]['text']}\n",
    "</texts>\n",
    "</author_samples>\n",
    "\n",
    "Now, analyze this new text and identify which author it most likely belongs to.\n",
    "\n",
    "<new_text>\n",
    "{random_text}\n",
    "</new_text>\n",
    "\n",
    "\n",
    "As an answer, give only the predicted id, no other text.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303162\n"
     ]
    }
   ],
   "source": [
    "first_prediction = get_completion(prompt)\n",
    "print(first_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted author id 303162 exists in the training set.\n"
     ]
    }
   ],
   "source": [
    "# Check if the model's predicted author id exsists\n",
    "author_ids = train_set['id'].unique()\n",
    "\n",
    "# Split the string by \"Author ID: \" and take the second part\n",
    "id_part = first_prediction.split(\"Author ID: \")[1]\n",
    "# Split by newline and take the first part to get just the number\n",
    "predicted_id = int(id_part.split('\\n')[0].strip())\n",
    "\n",
    "if predicted_id in author_ids:\n",
    "    print(f\"The predicted author id {predicted_id} exists in the training set.\")\n",
    "else:\n",
    "    print(f\"The predicted author id {predicted_id} does not exist in the training set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's prediction is incorrect.\n"
     ]
    }
   ],
   "source": [
    "# Assess the accuracy of the model's prediction\n",
    "\n",
    "if predicted_id == random_id:\n",
    "    print(\"The model's prediction is correct.\")\n",
    "else:\n",
    "    print(\"The model's prediction is incorrect.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 10 iterations\n",
      "Completed 20 iterations\n",
      "Completed 30 iterations\n",
      "Completed 40 iterations\n",
      "Completed 50 iterations\n",
      "Completed 60 iterations\n",
      "Completed 70 iterations\n",
      "Completed 80 iterations\n",
      "Completed 90 iterations\n",
      "Completed 100 iterations\n"
     ]
    }
   ],
   "source": [
    "# Create an experiment with 100 predictions\n",
    "\n",
    "# Initialize an empty list to store all predictions\n",
    "all_predictions = []\n",
    "\n",
    "# Loop through 100 iterations\n",
    "for i in range(100):\n",
    "    try:\n",
    "        # Select a random row from test_set\n",
    "        random_row = test_set.sample(n=1, random_state=i)  # Using i as random_state for reproducibility\n",
    "        random_text = random_row['text'].iloc[0]\n",
    "        random_id = random_row['id'].iloc[0]\n",
    "        \n",
    "        # Get the prediction from the model\n",
    "        prediction = get_completion(prompt)\n",
    "        \n",
    "        # Check if prediction is empty\n",
    "        if not prediction:\n",
    "            print(f\"Iteration {i}: Empty prediction received\")\n",
    "            continue\n",
    "            \n",
    "        # Try to convert the prediction to integer\n",
    "        try:\n",
    "            predicted_id = int(prediction)\n",
    "        except ValueError:\n",
    "            print(f\"Iteration {i}: Invalid prediction format: {prediction}\")\n",
    "            continue\n",
    "            \n",
    "        # Store the results\n",
    "        all_predictions.append({\n",
    "            'actual_id': random_id,\n",
    "            'predicted_id': predicted_id,\n",
    "            'is_correct': random_id == predicted_id\n",
    "        })\n",
    "        \n",
    "        # Print progress every 10 iterations\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"Completed {i + 1} iterations\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Iteration {i}: Error occurred - {str(e)}\")\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall accuracy: 8.00%\n",
      "Total predictions: 100\n",
      "Correct predictions: 8\n"
     ]
    }
   ],
   "source": [
    "# Check if we have any predictions\n",
    "if not all_predictions:\n",
    "    print(\"No valid predictions were collected\")\n",
    "else:\n",
    "    # Convert the list of predictions to a DataFrame\n",
    "    predictions_df = pd.DataFrame(all_predictions)\n",
    "    \n",
    "    # Calculate and print overall accuracy\n",
    "    accuracy = predictions_df['is_correct'].mean()\n",
    "    print(f\"\\nOverall accuracy: {accuracy:.2%}\")\n",
    "    print(f\"Total predictions: {len(predictions_df)}\")\n",
    "    print(f\"Correct predictions: {predictions_df['is_correct'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random guessing accuracy: 10.00%\n",
      "Accuracy guessing the most frequent author: 303162\n"
     ]
    }
   ],
   "source": [
    "# Determine what would be the accuracy by random guessing\n",
    "accuracy_random = 1 / len(author_ids) * 100\n",
    "print(f\"Random guessing accuracy: {accuracy_random:.2%}\")\n",
    "\n",
    "# Determine what would be the accuracy by guessing the most frequent author\n",
    "most_frequent_author = train_set['id'].mode()[0]\n",
    "accuracy_most_frequent = train_set[train_set['id'] == most_frequent_author]['id'].count() / len(author_ids) * 100\n",
    "print(f\"Accuracy guessing the most frequent author: {accuracy_most_frequent:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
